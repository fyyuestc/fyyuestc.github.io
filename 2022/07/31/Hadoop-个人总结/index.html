

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Fyy">
  <meta name="keywords" content="">
  
    <meta name="description" content="一、Hadoop概念和特点概念Apache™Hadoop®项目为可靠的，可扩展的分布式计算开发开源软件。 Apache Hadoop软件库是一个框架，它允许使用简单的编程模型跨计算机群集分布式处理大型数据集。它旨在从单个服务器扩展到数千台机器，每台机器提供本地计算和存储。该库本身不是依靠硬件来提供高可用性，而是设计用于在应用层检测和处理故障，从而在一组计算机之上提供高可用性服务，每个计算机都可能出">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop-个人总结">
<meta property="og:url" content="http://example.com/2022/07/31/Hadoop-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/index.html">
<meta property="og:site_name" content="UESTC-Fyy">
<meta property="og:description" content="一、Hadoop概念和特点概念Apache™Hadoop®项目为可靠的，可扩展的分布式计算开发开源软件。 Apache Hadoop软件库是一个框架，它允许使用简单的编程模型跨计算机群集分布式处理大型数据集。它旨在从单个服务器扩展到数千台机器，每台机器提供本地计算和存储。该库本身不是依靠硬件来提供高可用性，而是设计用于在应用层检测和处理故障，从而在一组计算机之上提供高可用性服务，每个计算机都可能出">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311428598.png">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311417085.png">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311421937.png">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311422324.png">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311422809.png">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311422910.gif">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311429550.png">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311432821.png">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311434452.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311434829.png">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311435709.png">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311446271.png">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311447354.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311447502.png">
<meta property="article:published_time" content="2022-07-31T05:30:37.000Z">
<meta property="article:modified_time" content="2022-08-26T08:37:35.892Z">
<meta property="article:author" content="Fyy">
<meta property="article:tag" content="PersonalSummary">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311428598.png">
  
  
  <title>Hadoop-个人总结 - UESTC-Fyy</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"DKnIWAmLCrVnCLIBVwd8hotg-gzGzoHsz","app_key":"9xmUpEdyRJB2o9bIKREcXk3j","server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 6.1.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>UESTC-Fyy-Master</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Hadoop-个人总结"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-07-31 13:30" pubdate>
          2022年7月31日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          18k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          151 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Hadoop-个人总结</h1>
            
            <div class="markdown-body">
              
              <h1 id="一、Hadoop概念和特点"><a href="#一、Hadoop概念和特点" class="headerlink" title="一、Hadoop概念和特点"></a>一、Hadoop概念和特点</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Apache™Hadoop®项目为<strong>可靠</strong>的，<strong>可扩展</strong>的<strong>分布式计算</strong>开发开源软件。</p>
<p>Apache Hadoop软件库是一个框架，它允许使用简单的编程模型跨计算机群集分布式处理大型数据集。它旨在从单个服务器扩展到数千台机器，每台机器提供本地计算和存储。该库本身不是依靠硬件来提供高可用性，而是设计用于在应用层检测和处理故障，从而在一组计算机之上提供高可用性服务，每个计算机都可能出现故障。</p>
<h2 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h2><ul>
<li><strong>Hadoop Common</strong>：支持其他Hadoop模块的常用工具。</li>
<li><strong>Hadoop分布式文件系统（HDFS™）</strong>：一种分布式文件系统，可提供对应用程序数据的高吞吐量访问。</li>
<li><strong>Hadoop YARN</strong>：作业调度和集群资源管理的框架。</li>
<li><strong>Hadoop MapReduce</strong>：一种用于并行处理大型数据集的基于YARN的系统。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311428598.png" srcset="/img/loading.gif" lazyload alt="image-20220731142820117"></p>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li><strong>扩容能力（Scalable）</strong>：能可靠地（reliably）存储和处理千兆字节（PB）数据。</li>
<li><strong>成本低（Economical）</strong>：可以通过普通机器组成的服务器群来分发以及处理数据。这些服务器群总计可达数千个节点。</li>
<li><strong>高效率（Efficient）</strong>：通过分发数据，hadoop可以在数据所在的节点上并行地（parallel）处理它们，这使得处理非常的快速。</li>
<li><strong>可靠性（Reliable）</strong>：hadoop能自动地维护数据的多份复制，并且在任务失败后能自动地重新部署（redeploy）计算任务。</li>
</ul>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>不适合低延迟数据访问</li>
<li>无法高效存储大量小文件</li>
<li>不支持多用户写入及任意修改文件</li>
</ul>
<h2 id="Hadoop编年史"><a href="#Hadoop编年史" class="headerlink" title="Hadoop编年史"></a>Hadoop编年史</h2><ul>
<li>2002 年 10 月，Doug Cutting 和 Mike Cafarella 创建了开源网页爬虫项目 Nutch。</li>
<li>2003 年 10 月，Google 发表 Google File System 论文。</li>
<li>2004 年 7 月，Doug Cutting 和 Mike Cafarella 在 Nutch 中实现了类似 GFS 的功能，即后来 HDFS 的前身。</li>
<li>2004 年 10 月，Google 发表了 MapReduce 论文。</li>
<li>2005 年 2 月，Mike Cafarella 在 Nutch 中实现了 MapReduce 的最初版本。</li>
<li>2005 年 12 月，开源搜索项目 Nutch 移植到新框架，使用 MapReduce 和 NDFS(Nutch Distributed File System ) 来运行，在 20 个节点稳定运行。</li>
<li>2006 年 1 月，Doug Cutting 加入雅虎，Yahoo! 提供一个专门的团队和资源将 Hadoop 发展成一个可在网络上运行的系统。</li>
<li><strong>2006年 2月，Apache Hadoop项目正式启动以支持 MapReduce和 HDFS 的独立发展。</strong></li>
<li>2006 年 2 月，Yahoo! 的网格计算团队采用 Hadoop。</li>
<li>2006 年 3 月，Yahoo! 建设了第一个 Hadoop 集群用于开发。</li>
<li>2006 年 4 月，第一个 Apache Hadoop 发布。</li>
<li>2006 年 4 月，在 188 个节点上（每个节点 10GB）运行排序测试集需要 47.9 个小时。</li>
<li>2006 年 5 月，Yahoo! 建立了一个 300 个节点的 Hadoop 研究集群。</li>
<li>2006 年 5 月，在 500 个节点上运行排序测试集需要 42 个小时（硬件配置比 4 月的更好）。</li>
<li>2006 年 11 月，研究集群增加到 600 个节点。</li>
<li>2006 年 11 月，Google 发表了 Bigtable 论文，这最终激发了 HBase 的创建。</li>
<li>2006 年 12 月，排序测试集在 20 个节点上运行 1.8 个小时，100 个节点上运行 3.3 小时，500 个节点上运行 5.2 小时，900 个节点上运行 7.8 个小时。</li>
<li>2007 年 1 月，研究集群增加到 900 个节点。</li>
<li>2007 年 4 月，研究集群增加到两个 1000 个节点的集群。</li>
<li><strong>2007年 10月，第一个 Hadoop 用户组会议召开，社区贡献开始急剧上升。</strong></li>
<li>2007 年，百度开始使用 Hadoop 做离线处理。</li>
<li>2007 年，中国移动开始在“大云”研究中使用 Hadoop 技术。</li>
<li>2008 年，淘宝开始投入研究基于 Hadoop 的系统——云梯，并将其用于处理电子商务相关数据。</li>
<li><strong>2008年 1月，Hadoop成为 Apache顶级项目。</strong></li>
<li>2008 年 2 月，Yahoo! 运行了世界上最大的 Hadoop 应用，宣布其搜索引擎产品部署在一个拥有 1 万个内核的 Hadoop 集群上。</li>
<li>2008 年 4 月，在 900 个节点上运行 1TB 排序测试集仅需 209 秒，成为世界最快。</li>
<li>2008 年 6 月，Hadoop 的第一个 SQL 框架——Hive 成为了 Hadoop 的子项目。</li>
<li>2008 年 7 月，Hadoop 打破 1TB 数据排序基准测试记录。Yahoo! 的一个 Hadoop 集群用 209 秒完成 1TB 数据的排序 ，比上一年的纪录保持者保持的 297 秒快了将近 90 秒。</li>
<li><strong>2008年 8月，第一个 Hadoop商业化公司 Cloudera成立。</strong></li>
<li>2008 年 10 月，研究集群每天装载 10TB 的数据。</li>
<li>2008 年 11 月，Apache Pig 的最初版本发布。</li>
<li>2009 年 3 月，17 个集群总共 24000 台机器。</li>
<li><strong>2009</strong> <strong>年 3月，Cloudera推出世界上首个 Hadoop发行版——CDH（Cloudera’s Distribution including Apache Hadoop）平台，完全由开放源码软件组成。</strong></li>
<li>2009 年 4 月，赢得每分钟排序，59 秒内排序 500GB（在 1400 个节点上）和 173 分钟内排序 100TB 数据（在 3400 个节点上）。</li>
<li>2009 年 5 月，Yahoo 的团队使用 Hadoop 对 1 TB 的数据进行排序只花了 62 秒时间。</li>
<li>2009 年 6 月，Cloudera 的工程师 Tom White 编写的《Hadoop 权威指南》初版出版，后被誉为 Hadoop 圣经。</li>
<li>2009 年 7 月 ，Hadoop Core 项目更名为 Hadoop Common;</li>
<li>2009 年 7 月 ，MapReduce 和 Hadoop Distributed File System (HDFS) 成为 Hadoop 项目的独立子项目。</li>
<li>2009 年 7 月 ，Avro 和 Chukwa 成为 Hadoop 新的子项目。</li>
<li>2009 年 8 月，Hadoop 创始人 Doug Cutting 加入 Cloudera 担任首席架构师。</li>
<li>2009 年 10 月，首届 Hadoop World 大会在纽约召开。</li>
<li>2010 年 5 月 ，Avro 脱离 Hadoop 项目，成为 Apache 顶级项目。</li>
<li>2010 年 5 月 ，HBase 脱离 Hadoop 项目，成为 Apache 顶级项目。</li>
<li>2010 年 5 月，IBM 提供了基于 Hadoop 的大数据分析软件——InfoSphere BigInsights，包括基础版和企业版。</li>
<li>2010 年 9 月，Hive( Facebook) 脱离 Hadoop，成为 Apache 顶级项目。</li>
<li>2010 年 9 月，Pig 脱离 Hadoop，成为 Apache 顶级项目。</li>
<li><strong>2010年 -2011年，扩大的 Hadoop社区忙于建立大量的新组件（Crunch，Sqoop，Flume，Oozie</strong>等）来扩展 Hadoop<strong>的使用场景和可用性。</strong></li>
<li>2011 年 1 月，ZooKeeper 脱离 Hadoop，成为 Apache 顶级项目。</li>
<li>2011 年 3 月，Apache Hadoop 获得 Media Guardian Innovation Awards 。</li>
<li>2011 年 3 月， Platform Computing 宣布在它的 Symphony 软件中支持 Hadoop MapReduce API。</li>
<li><strong>2011年 5月，Mapr Technologies公司推出分布式文件系统和 MapReduce引擎——MapR Distribution for Apache Hadoop。</strong></li>
<li>2011 年 5 月，HCatalog 1.0 发布。该项目由 Hortonworks 在 2010 年 3 月份提出，HCatalog 主要用于解决数据存储、元数据的问题，主要解决 HDFS 的瓶颈，它提供了一个地方来存储数据的状态信息，这使得 数据清理和归档工具可以很容易的进行处理。</li>
<li>2011 年 4 月，SGI（Silicon Graphics International）基于 SGI Rackable 和 CloudRack 服务器产品线提供 Hadoop 优化的解决方案。</li>
<li>2011 年 5 月，EMC 为客户推出一种新的基于开源 Hadoop 解决方案的数据中心设备——GreenPlum HD，以助其满足客户日益增长的数据分析需求并加快利用开源数据分析软件。Greenplum 是 EMC 在 2010 年 7 月收购的一家开源数据仓库公司。</li>
<li>2011 年 5 月，在收购了 Engenio 之后， NetApp 推出与 Hadoop 应用结合的产品 E5400 存储系统。</li>
<li>2011 年 6 月，Calxeda 公司发起了“开拓者行动”，一个由 10 家软件公司组成的团队将为基于 Calxeda 即将推出的 ARM 系统上芯片设计的服务器提供支持。并为 Hadoop 提供低功耗服务器技术。</li>
<li>2011 年 6 月，数据集成供应商 Informatica 发布了其旗舰产品，产品设计初衷是处理当今事务和社会媒体所产生的海量数据，同时支持 Hadoop。</li>
<li><strong>2011年 7月，Yahoo!和硅谷风险投资公司 Benchmark Capital创建了 Hortonworks</strong> <strong>公司，旨在让 Hadoop更加可靠，并让企业用户更容易安装、管理和使用 Hadoop。</strong></li>
<li>2011 年 8 月，Cloudera 公布了一项有益于合作伙伴生态系统的计划——创建一个生态系统，以便硬件供应商、软件供应商以及系统集成商可以一起探索如何使用 Hadoop 更好的洞察数据。</li>
<li>2011 年 8 月，Dell 与 Cloudera 联合推出 Hadoop 解决方案——Cloudera Enterprise。Cloudera Enterprise 基于 Dell PowerEdge C2100 机架服务器以及 Dell PowerConnect 6248 以太网交换机。</li>
<li>2012 年 3 月，企业必须的重要功能 HDFS NameNode HA 被加入 Hadoop 主版本。</li>
<li>2012 年 8 月，另外一个重要的企业适用功能 YARN 成为 Hadoop 子项目。</li>
<li>2012 年 10 月，第一个 Hadoop 原生 MPP 查询引擎 Impala 加入到了 Hadoop 生态圈。</li>
<li><strong>2014年 2月，Spark逐渐代替 MapReduce成为 Hadoop的缺省执行引擎，并成为 Apache基金会顶级项目。</strong></li>
<li>2015 年 2 月，Hortonworks 和 Pivotal 抱团提出“Open Data Platform”的倡议，受到传统企业如 Microsoft、IBM 等企业支持，但其它两大 Hadoop 厂商 Cloudera 和 MapR 拒绝参与。</li>
<li>2015 年 10 月，Cloudera 公布继 HBase 以后的第一个 Hadoop 原生存储替代方案——Kudu。</li>
<li>2015 年 12 月，Cloudera 发起的 Impala 和 Kudu 项目加入 Apache 孵化器。</li>
</ul>
<h1 id="二、Hadoop体系架构"><a href="#二、Hadoop体系架构" class="headerlink" title="二、Hadoop体系架构"></a>二、Hadoop体系架构</h1><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Hadoop Distributed File System(HDFS)是一个运行在商用硬件平台上的分布式文件系统。它和很多现存的分布式文件系统有很多相似之处。当然，和其他的分布式文件系统的区别也是很明显的。HDFS在廉价硬件平台上提供高可靠的文件服务，提供数据访问的高吞吐量，适合那些运行在大数据集上的应用。HDFS并不完全符合POSIX文件系统方面的标准，这是因为HDFS运行环境和POSIX filesystem适用的环境是不同。HDFS支持对文件系统数据的流式访问。HDFS最初是为Apache Nutch搜索引擎项目设计的。现在HDFS是Apache Hadoop的一个子项目。</p>
<h3 id="假定和目标"><a href="#假定和目标" class="headerlink" title="假定和目标"></a>假定和目标</h3><p><strong>Hardware Failure</strong></p>
<p>硬件失效是很普通的情况而不是什么异常。HDFS运行环境可能包含数百台服务器，每台机器存储着文件系统的部分数据。事实上这些服务器的数据已经很大了，而且每一台机器都有不小的可能性会失败，这就导致HDFS部件并不总是正常工作的。因此，检测失败并且能够迅速的恢复是HDFS的核心设计目标。</p>
<p><strong>Stream Data Access</strong></p>
<p>运行在HDFS上的应用需要流式的访问他们的数据集。HDFS应用不像 那些在通用的文件系统上操作的应用。HDFS是面向批处理操作而不是那些user交互操作。HDFS侧重于高吞吐量而不是低延迟。POSIX标准的一些需求并不适合面向HDFS的应用，因此为了达到高吞吐量而在某些方面违反了Posix 标准。</p>
<p><strong>Large Data Sets</strong></p>
<p>运行在HDFS上的应用操纵的都是大数据集。一个典型的HDFS文件的尺寸是GB~TB大小。因此，HDFS针对大文件进行了优化。通过把一个文件分散到集群内的数千个节点，来提供更高的数据带宽。HDFS应该能够支持千万级的文件数目。</p>
<p><strong>Append-writes and File Syncs</strong></p>
<p>大部分HDFS应用的文件操作模式是写一次读多次。HDFS提供了两个高级功能：hflush和append。hflush提供read一致性和数据持久性。使得文件的最后一块对文件的读用户都可见。Append提供了一种机制能够重新打开关闭的文件添加额外的数据。</p>
<p><strong>Move Computation is Cheaper than Moving Data</strong></p>
<p>当计算在数据保存的节点附近时，效率会更高，尤其当操作的数据非常大的时候。就近计算使得网络消耗和系统吞吐量都最小。根据这个原则，移动计算到数据的保存位置而不是把数据移动到计算节点。HDFS向应用提供了接口：移动计算到数据存放位置。</p>
<p><strong>Protability Across Heterogeneous Hardware and Software Platforms</strong></p>
<p>HDFS很容易的在不同平台移植。这个特性使得HDFS被很多应用采纳为平台。</p>
<h3 id="NameNode-and-DataNodes"><a href="#NameNode-and-DataNodes" class="headerlink" title="NameNode and DataNodes"></a>NameNode and DataNodes</h3><p>HDFS采用master&#x2F;slave体系结构。HDFS集群包含一个NameNode，用来管理文件系统的名空间以及管理Clients访问文件的权限。此外，HDFS还包括一定数目的DataNodes，用来管理所在机器的存储空间（通常每台机器只有一个DataNodes）。HDFS通过Namenode向用户提供一个 文件系统名空间，允许用户存储数据为HDFS files。在HDFS内部，一个文件则被分割成很多块，这些块被存储在多个DataNodes中。Namenode执行文件系统名空间操做如open, close, rename文件和目录，同时负责到DataNodes节点的块映射。DataNodes负责Client读写数据请求，DataNodes还会执行block的创建，删除以及在block的复制。</p>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311417085.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>NameNode和DataNode是运行在普通机器上的软件，这些机器一般为GNU&#x2F;Linux操作系统。HDFS是用Java语言实现的，因此任何支持Java的机器都可以运行NameNode和DataNode软件。使用移植性很强的Java语言意味着HDFS的可部署范围非常之广。典型的部署是NameNode使用一个特定的机器，集群中的其他机器节点，每一个上面运行一个DataNode。虽然HDFS架构本身并不排斥一台机器运行多个DataNode，但是实际部署中很少这样用。</p>
<p>集群中仅有一个NameNode极大的简化了系统架构。NameNode是系统的仲裁者，负责HDFS所有的元数据。NameData不会经手任何user data。</p>
<h2 id="数据复制（Data-Replication）"><a href="#数据复制（Data-Replication）" class="headerlink" title="数据复制（Data Replication）"></a>数据复制（Data Replication）</h2><p>HDFS能可靠的存储非常大的文件到集群中的多个机器上。每个文件被分割为连续的block，除了最后一块，文件中的每个块尺寸相同。文件的block被复制多份提供容错能力。可以为每一个文件指定块尺寸和复制因子，复制因子可以在文件创建的时候指定也可以在稍候修改。HDFS中的文件在任何时候只能有一个writer</p>
<p>NameNode决定何时做block复制。它周期性的从集群的每个DataNode接收Heartbeat和Block report。从DataNode接收到Heartbeat意味着DataNode工作正常。Block report包含一个DataNode的所有blocks列表。</p>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311421937.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><p>Apache YARN（Yet Another Resource Negotiator的缩写）是Hadoop的集群资源管理系统。YARN被引入Hadoop 2，最初是为了改善Map Reduce的实现，但他具有足够的通用性，同样可以支持其他的分布式计算模式。</p>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311422324.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>YARN 通过两类长期的守护进程提供自己的核心服务</p>
<ul>
<li>resource manager：管理集群上资源使用的资源管理器</li>
<li>node manager：运行在集群中所有节点上且能够启动和监控容器（container）的节点管理器。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311422809.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>为了在YARN上运行一个应用。首先，客户端联系资源管理器，要求他运行一个application master进程。然后资源管理器找到一个能够在容器中启动application master的节点管理器（步骤2a和2b）。准确的说，application master一旦运行起来以后能做什么依赖于应用本身。有可能是所处容器中简单运行一个运算，然后将结果返回给客户端。或者向资源管理器请求更多的容器（步骤3），以用于运行一个分布式计算（步骤4a和4b）。</p>
<p>YARN的基本构想是将资源管理器和作业调度器&#x2F;监控器分开成两个单独的进程。这个想法是为了拥有一个全局的资源管理器（RM）和每一个应用都有一个应用控制器。应用可以是一个单独的作业也可以是一组作业。</p>
<p>ResourceManager和NodeManager构成数据计算框架。RM是最终的权威仲裁系统中的所有应用的资源分配。NodeManager是框架在每台机器中负责containers的代理，监控它们的资源使用（内存、CPU、磁盘和网络）和将其汇报给ResourceManager&#x2F;调度器。</p>
<p>每个应用程序的ApplicationMaster实际上是框架指定的库负责从RM谈判获取资源并和MM一起工作来执行和监控任务。</p>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311422910.gif" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>ResourceManager有两个主要的组成部分：调度器(Scheduler)和应用管理器(ApplicationsManager)。</p>
<p>调度器负责给各个正在运行的拥有相似的约束如容量，队列等的应用分配资源。调度器是一个纯粹的调度器而不负责监控或者跟踪应用的状态。他也不负责恢复由于应用失效或者硬件失效而失败的任务。调度器根据应用的资源需求来执行它的调度。而不是根据一个抽象资源“容器”包含的元素例如内存、CPU、磁盘和网络等</p>
<p>调度器是一个可插拔的组件负责将资源分配给各种各样的队列、应用等。目前的容量调度器和公平调度器将成为一些插件的例子。</p>
<p>应用管理器负责接收作业的提交、选择第一个容器用来运行应用指定的应用控制器和提供当ApplicationMaster容器失效时的重启。每个应用的ApplicationMaster负责从调度器那里谈判获取合适的资源容器，跟踪他们的状态和监控过程。</p>
<p>hadoop-2.x中的MapReduce兼容前面稳定的版本（hadoop-1.x）。这就意味着所有的MapReduce作业只需要再编译一次无需做任何改变就可以运行在YARN上。</p>
<h1 id="三、常见大数据产品框架"><a href="#三、常见大数据产品框架" class="headerlink" title="三、常见大数据产品框架"></a>三、常见大数据产品框架</h1><p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311429550.png" srcset="/img/loading.gif" lazyload alt="Hadoop大数据应用生态中最主要的组件及其关系"></p>
<p><strong>HDFS（Hadoop分布式文件系统）</strong></p>
<p>源自于Google的GFS论文，发表于2003年10月，HDFS是GFS的实现版。HDFS是Hadoop体系中数据存储管理的基础，它是一个高度容错的系统，能检测和应对硬件故障，在低成本的通用硬件上运行。HDFS简化了文件的一致性模型，通过流式数据访问，提供高吞吐量应用程序数据访问功能，适合带有大型数据集的应用程序。HDFS提供一次写入多次读取的机制，数据以块的形式，同时分布存储在集群的不同物理机器上。</p>
<p><strong>MapReduce（分布式计算框架）</strong></p>
<p>源自于Google的MapReduce论文，发表于2004年12月，HadoopMapReduce是GoogleMapReduce克隆版。MapReduce是一种分布式计算模型，用以进行海量数据的计算。它屏蔽了分布式计算框架细节，将计算抽象成Map和Reduce两部分，其中Map对数据集上的独立元素进行指定的操作，生成键值对形式中间结果。Reduce则对中间结果中相同“键”的所有“值”进行规约，以得到最终结果。</p>
<p><strong>HBase（分布式列存数据库）</strong></p>
<p>源自Google的BigTable论文，发表于2006年11月，HBase是GoogleBigTable的实现。HBase是一个建立在HDFS之上，面向结构化数据的可伸缩、高可靠、高性能、分布式和面向列的动态模式数据库。HBase采用了BigTable的数据模型，即增强的稀疏排序映射表（Key&#x2F;Value），其中，键由行关键字、列关键字和时间戳构成。HBase提供了对大规模数据的随机、实时读写访问，同时，HBase中保存的数据可以使用MapReduce来处理，它将数据存储和并行计算完美地结合在一起。</p>
<p><strong>ZooKeeper（分布式协作服务）</strong></p>
<p>源自Google的Chubby论文，发表于2006年11月，ZooKeeper是Chubby实现版。ZooKeeper的主要目标是解决分布式环境下的数据管理问题，如统一命名、状态同步、集群管理、配置同步等。Hadoop的许多组件依赖于ZooKeeper，它运行在计算机集群上面，用于管理Hadoop操作。</p>
<p><strong>Hive（数据仓库）</strong></p>
<p>由Facebook开源，最初用于解决海量结构化的日志数据统计问题。Hive定义了一种类似SQL的查询语言（HQL），将SQL转化为MapReduce任务在Hadoop上执行，通常用于离线分析。HQL用于运行存储在Hadoop上的查询语句，Hive使不熟悉MapReduce开发人员也能编写数据查询语句，然后这些语句被翻译为Hadoop上面的MapReduce任务。</p>
<p><strong>Pig（adhoc脚本）</strong></p>
<p>由yahoo开源，其设计动机是提供一种基于MapReduce的adhoc（计算在query时发生）数据分析工具。Pig定义了一种数据流语言——PigLatin，它是MapReduce编程的复杂性的抽象，Pig平台包括运行环境和用于分析Hadoop数据集的脚本语言（PigLatin）。其编译器将PigLatin翻译成MapReduce程序序列，将脚本转换为MapReduce任务在Hadoop上执行，通常用于进行离线分析。</p>
<p><strong>Sqoop（数据ETL&#x2F;同步工具）</strong></p>
<p>是SQL to Hadoop的缩写，主要用于传统数据库和Hadoop之前传输数据。数据的导入和导出本质上是MapReduce程序，充分利用了MR的并行化和容错性。Sqoop利用数据库技术描述数据架构，用于在关系数据库、数据仓库和Hadoop之间转移数据。</p>
<p><strong>Flume（日志收集工具）</strong></p>
<p>是Cloudera开源的日志收集系统，具有分布式、高可靠、高容错、易于定制和扩展的特点。它将数据从产生、传输、处理并最终写入目标的路径的过程抽象为数据流，在具体的数据流中，数据源支持在Flume中定制数据发送方，从而支持收集各种不同协议数据。同时，Flume数据流提供对日志数据进行简单处理的能力，如过滤、格式转换等。此外，Flume还具有能够将日志写往各种数据目标（可定制）的能力。总的来说，Flume是一个可扩展、适合复杂环境的海量日志收集系统，当然也可以用于收集其他类型数据。</p>
<p><strong>Mahout（数据挖掘算法库）</strong></p>
<p>起源于2008年，最初是ApacheLucent的子项目，它在极短的时间内取得了长足的发展，现在是Apache的顶级项目。Mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便、快捷地创建智能应用程序。Mahout现在已经包含了聚类、分类、推荐引擎（协同过滤）和频繁集挖掘等广泛使用的数据挖掘方法。除了算法，Mahout还包含数据的输入&#x2F;输出工具、与其他存储系统（如数据库、MongoDB或Cassandra）集成的数据挖掘支持架构。</p>
<p><strong>YARN（分布式资源管理器）</strong></p>
<p>是下一代MapReduce，即MRv2，是在第一代MapReduce基础上演变而来的，主要是为了解决原始Hadoop扩展性较差，不支持多计算框架而提出的。YARN是下一代Hadoop计算平台，是一个通用的运行时框架，用户可以编写自己的计算框架，在该运行环境中运行。</p>
<p><strong>Mesos（分布式资源管理器）</strong></p>
<p>是一个诞生于UCBerkeley的研究项目，现已成为Apache项目，当前有一些公司使用Mesos管理集群资源，如Twitter。与YARN类似，Mesos是一个资源统一管理和调度的平台，同样支持诸如MR、steaming等多种运算框架。</p>
<p><strong>Spark（内存DAG计算模型）</strong></p>
<p>是一个Apache项目，被标榜为“快如闪电的集群计算”，它拥有一个繁荣的开源社区，并且是目前最活跃的Apache项目。最早Spark是UCBerkeleyAMPLab所开源的类HadoopMapReduce的通用并行计算框架，Spark提供了一个更快、更通用的数据处理平台。和Hadoop相比，Spark可以让你的程序在内存中运行时速度提升100倍，或者在磁盘上运行时速度提升10倍。</p>
<p><strong>SparkGraphX</strong></p>
<p>最先是伯克利AMPLab的一个分布式图计算框架项目，目前整合在Spark运行框架中，为其提供BSP大规模并行图计算能力。</p>
<p><strong>SparkMLlib</strong></p>
<p>一个机器学习库，它提供了各种各样的算法，这些算法用来在集群上针对分类、回归、聚类、协同过滤等。</p>
<p><strong>Kafka</strong></p>
<p>Linkedin于2010年12月开源的消息系统，主要用于处理活跃的流式数据。活跃的流式数据在Web网站应用中非常常见，这些数据包括网站的PV（PageView），用户访问了什么内容，搜索了什么内容等。这些数据通常以日志的形式记录下来，然后每隔一段时间进行一次统计处理。</p>
<p><strong>ApachePhoenix</strong></p>
<p>HBase的SQL驱动（HBaseSQL接口）,Phoenix使得HBase支持通过JDBC的方式进行访问，并将你的SQL查询转换成HBase的扫描和相应的动作。</p>
<p><strong>ApacheAmbari</strong></p>
<p>安装部署配置管理工具，其作用就是创建、管理、监视Hadoop的集群，是为了让Hadoop以及相关的大数据软件更容易使用的一个Web工具。</p>
<h1 id="四、HDFS"><a href="#四、HDFS" class="headerlink" title="四、HDFS"></a>四、HDFS</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>HDFS即Hadoop分布式文件系统（Hadoop Distributed File System），它的设计目标是把超大数据集存储到网络中的多台普通商用计算机上，并提供高可靠性和高吞吐率的服务。分布式文件系统要比普通磁盘文件系统复杂，因为它要引入网络编程；分布式文件系统要容忍节点失效，这也是一个很大的挑战。</p>
<p><strong>HDFS的设计前提和目标如下。</strong></p>
<p>（1）专为存储超大文件而设计：HDFS应该能够支持GB级别大小的文件；它应该能够提供很大的数据带宽并且能够在集群中拓展到成百上千个节点；它的一个实例应该能够支持千万数量级别的文件。</p>
<p>（2）适用于流式的数据访问：HDFS适用于批处理的情况而不是交互式处理；它的重点是保证高吞吐量而不是低延迟的用户响应。</p>
<p>（3）容错性：完善的冗余备份机制。</p>
<p>（4）支持简单的一致性模型：HDFS需要支持一次写入多次读取的模型，而且写入过程文件不会经常变化。</p>
<p>（5）移动计算优于移动数据：HDFS提供了使应用计算移动到离它最近数据位置的接口。</p>
<p>（6）兼容各种硬件和软件平台。</p>
<p><strong>HDFS不适合的场景如下。</strong></p>
<p>（1）大量小文件：文件的元数据都存储在NameNode内存中，大量小文件意味着元数据的增加，会占用大量内存。</p>
<p>（2）低延迟数据访问：HDFS是专门针对高数据吞吐量而设计的。</p>
<p>（3）多用户写入：因为会导致一致性维护的困难。</p>
<h2 id="主要组件和架构"><a href="#主要组件和架构" class="headerlink" title="主要组件和架构"></a>主要组件和架构</h2><p>HDFS主要由3个组件构成，分别是Name Node、SecondaryNameNode和DataNode, HDFS是以Master&#x2F;Slave（主从）模式运行的，其中NameNode、SecondaryNameNode运行在Master节点，DataNode运行Slave节点上。NameNode和DataNode架构如图所示。</p>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311432821.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h2 id="HDFS架构分析"><a href="#HDFS架构分析" class="headerlink" title="HDFS架构分析"></a>HDFS架构分析</h2><h3 id="数据块（Block）"><a href="#数据块（Block）" class="headerlink" title="数据块（Block）"></a>数据块（Block）</h3><p>磁盘数据块是磁盘读写的基本单位，与普通文件系统类似，HDFS也会把文件分块来存储。HDFS默认数据块大小为128MB，而磁盘块一般为512B。HDFS块为何如此之大呢？块增大可以减少寻址时间与文件传输时间的比例，若寻址时间为10ms，磁盘传输速率为100MB&#x2F;s，那么寻址与传输比仅为1%。当然，磁盘块太大也不好，因为一个MapReduce通常以一个块作为输入，块过大会导致整体任务数量过小，降低作业处理速度。数据块是存储在DataNode中的，为了能够容错，数据块是以多个副本的形式分布在集群中的，副本数量默认为3，后面会专门介绍数据块的复制机制。HDFS按块存储还有如下好处。</p>
<ul>
<li>文件可以任意大，也不用担心单个节点磁盘容量小于文件的情况。</li>
<li>简化了文件子系统的设计，子系统只存储文件块数据，而文件元数据则交由其他系统（NameNode）管理。</li>
<li>有利于备份和提高系统可用性，这得益于以块为单位进行备份的设计，HDFS默认备份数量为3。</li>
<li>有利于负载均衡。</li>
</ul>
<h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><p>NameNode中的元信息当一个客户端请求一个文件或者存储一个文件时，它需要先知道具体到哪个DataNode上存取，获得这些信息后，客户端再直接和这个DataNode进行交互，而这些信息的维护者就是NameNode。NameNode管理着文件系统的命名空间，它维护文件系统树及树中的所有文件和目录。NameNode也负责维护所有这些文件或目录的打开、关闭、移动、重命名等操作。对于实际文件数据的保存与操作，都是由DataNode负责的。当一个客户端请求数据时，它仅仅是从NameNode中获取文件的元信息，而具体的数据传输不需要经过NameNode，是由客户端直接与相应的DataNode进行交互的。</p>
<p>NameNode保存元信息的种类有：</p>
<ul>
<li>文件名目录名及它们之间的层级关系；</li>
<li>文件目录的所有者及其权限；</li>
<li>每个文件块的名及文件有哪些块组成。</li>
</ul>
<p>需要注意的是，NameNode元信息并不包含每个块的位置信息，这些信息会在NameNode启动时从各个DataNode获取并保存在内存中，因为这些信息会在系统启动时由数据节点重建。把块位置信息放在内存中，在读取数据时会减少查询时间，增加读取效率。</p>
<p>NameNode也会实时通过心跳机制和DataNode进行交互，实时检查文件系统是否运行正常。不过NameNode元信息会保存各个块的名称及文件由哪些块组成。一般来说，一条元信息记录会占用200B内存空间。假设块大小为64MB，备份数量是3，那么一个1GB大小的文件将占用16×3&#x3D;48个文件块。如果现在有1000个1MB大小的文件，则会占用1000×3&#x3D;3000个文件块（多个文件不能放到一个块中）。我们可以发现，如果文件越小，存储同等大小文件所需要的元信息就越多，所以，Hadoop更喜欢大文件。</p>
<p>元信息的持久化在<strong>NameNode</strong>中存放元信息的文件是<strong>fsimage</strong>。在系统运行期间所有对元信息的操作都保存在内存中并被持久化到另一个文件<strong>edits</strong>中，并且edits文件和fsimage文件会被SecondaryNameNode周期性地合并（合并过程会在SecondaryNameNode中详细介绍）。运行NameNode会占用大量内存和I&#x2F;O资源，一般NameNode不会存储用户数据或执行MapReduce任务。为了简化系统的设计，Hadoop只有一个NameNode，这也就导致了Hadoop集群的单点故障问题。因此，对NameNode节点的容错尤其重要，Hadoop提供了如下两种机制来解决。</p>
<ul>
<li>将Hadoop元数据写入到本地文件系统的同时再实时同步到一个远程挂载的网络文件系统（NFS）。</li>
<li>运行一个SecondaryNameNode，它的作用是与NameNode进行交互，定期通过编辑日志文件合并命名空间镜像。当NameNode发生故障时，它会通过自己合并的命名空间镜像副本来恢复。需要注意的是SecondaryNameNode保存的状态总是滞后于NameNode，所以这种方式难免会导致丢失部分数据。</li>
</ul>
<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3><p>DataNode是HDFS中的Worker节点，它负责存储数据块，也负责为系统客户端提供数据块的读写服务，同时还会根据NameNode的指示来进行创建、删除和复制等操作。此外，它还会通过心跳定期向NameNode发送所存储文件块列表信息。当对HDFS文件系统进行读写时，NameNode告知客户端每个数据驻留在哪个DataNode，客户端直接与DataNode进行通信，DataNode还会与其他DataNode通信，复制这些块以实现冗余。</p>
<h3 id="SecondaryNameNode"><a href="#SecondaryNameNode" class="headerlink" title="SecondaryNameNode"></a>SecondaryNameNode</h3><p>要注意，SecondaryNameNode并不是NameNode的备份。我们从前面的介绍已经知道，所有HDFS文件的元信息都保存在NameNode的内存中。在NameNode启动时，它首先会加载<strong>fsimage</strong>到内存中，在系统运行期间，所有对NameNode的操作也都保存在内存中，同时为了防止数据丢失，这些操作又会不断被持久化到本地<strong>edits</strong>文件中。edits文件的目的是为了提高系统的操作效率，NameNode在更新内存中的元信息之前都会先将操作写入edits文件。在NameNode重启的过程中，edits会和fsimage合并到一起，但是合并的过程会影响到Hadoop重启的速度，SecondaryNameNode就是为了解决这个问题而诞生的。SecondaryNameNode的角色就是定期合并edits和fsimage文件，我们来看一下合并的步骤。</p>
<p>（1）合并之前告知NameNode把所有的操作写到新的edites文件并将其命名为edits.new。</p>
<p>（2）SecondaryNameNode从NameNode请求fsimage和edits文件。</p>
<p>（3）SecondaryNameNode把fsimage和edits文件合并成新的fsimage文件。</p>
<p>（4）NameNode从SecondaryNameNode获取合并好的新的fsimage并将旧的替换掉，并把edits用（1）创建的edits.new文件替换掉。</p>
<p>（5）更新fstime文件中的检查点。</p>
<p>最后再总结一下整个过程中涉及NameNode中的相关文件。</p>
<ul>
<li>fsimage：保存的是上个检查点的HDFS的元信息。</li>
<li>edits：保存的是从上个检查点开始发生的HDFS元信息状态改变信息。</li>
<li>fstime：保存了最后一个检查点的时间戳。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311434452.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<h2 id="文件操作流程"><a href="#文件操作流程" class="headerlink" title="文件操作流程"></a>文件操作流程</h2><h3 id="读文件"><a href="#读文件" class="headerlink" title="读文件"></a>读文件</h3><p>HDFS有一个文件系统实例，客户端通过调用这个实例的open（）方法就可以打开系统中希望读取的文件。HDFS通过RPC调用NameNode获取文件块的位置信息，对于文件的每一个块，NameNode会返回含有该块副本的DataNode的节点地址。另外，客户端还会根据网络拓扑来确定它与每一个DataNode的位置信息，从离它最近的那个DataNode获取数据块的副本，最理想的情况是数据块就存储在客户端所在的节点上。HDFS会返回一个FSDataInputStream对象，FSDataInputStream类转而封装成DFSDataInputStream对象，这个对象管理着与DataNode和NameNode的I&#x2F;O，具体过程是：</p>
<ul>
<li>客户端发起读请求。</li>
<li>客户端与NameNode得到文件的块及位置信息列表。</li>
<li>客户端直接和DataNode交互读取数据。</li>
<li>读取完成关闭连接。图42给出了上述读文件的过程示意。</li>
</ul>
<p>当FSDataInputStream与DataNode通信时遇到错误，它会选取另一个较近的DataNode，并为出故障的DataNode做标记以免重复向其读取数据。FSDataInputStream还会对读取的数据块进行校验和确认，发现块损坏时也会重新读取并通知NameNode。这样设计的巧妙之处有：</p>
<ul>
<li>让客户端直接联系DataNode检索数据，可以使HDFS扩展到大量的并发客户端，因为数据流就是分散在集群的每个节点上的，在运行MapReduce任务时，每个客户端就是一个DataNode节点。</li>
<li>NameNode仅需要相应块的位置信息请求（位置信息在内存中，速度极快），否则随着客户端的增加，NameNode会很快成为瓶颈。这里有必要理解Hadoop的网络拓扑。在海量数据处理过程中，主要限制因素是节点之间的带宽。衡量两个节点之间的带宽往往很难实现，在这里Hadoop采取了一个简单的方法，它把网络拓扑看成一棵树，两个节点的距离等于它们到最近共同祖先距离的总和，而树的层次可以这么划分：<ul>
<li>同一节点中的进程；</li>
<li>同一机架上的不同节点；</li>
<li>同一数据中心不同机架；</li>
<li>不同数据中心的节点。</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311434829.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h3 id="写文件"><a href="#写文件" class="headerlink" title="写文件"></a>写文件</h3><p>HDFS有一个分布式文件系统（Distribute File System,DFS）实例，客户端通过调用这个实例的create（）方法就可以创建文件。DFS会发送给NameNode一个RPC调用，在文件系统的命名空间创建一个新文件，在创建文件前NameNode会做一些检查，看看文件是否存在，客户端是否有创建权限等。若检查通过，NameNode会为创建文件写一条记录到本地磁盘的EditLog；若不通过会向客户端抛出IOException。创建成功之后DFS会返回一个FSDataOutputStream对象，客户端由此开始写入数据。同读文件过程一样，</p>
<p>FSDataOutputStream类转而封装成DFSDataOutputStream对象，这个对象管理着与DataNode和NameNode的I&#x2F;O，具体过程是：</p>
<ul>
<li>客户端在向NameNode请求之前先写入文件数据到本地文件系统的一个临时文件。</li>
<li>待临时文件达到块大小时开始向NameNode请求DataNode信息。</li>
<li>NameNode在文件系统中创建文件并返回给客户端一个数据块及其对应DataNode的地址列表（列表中包含副本存放的地址）。</li>
<li>客户端通过上一步得到的信息把创建临时文件块Flush到列表中的第一个DataNode。</li>
<li>当文件关闭，NameNode会提交这次文件创建，此时文件在文件系统中可见。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311435709.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h2 id="HDFS命令"><a href="#HDFS命令" class="headerlink" title="HDFS命令"></a>HDFS命令</h2><h3 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h3><p>创建目录用<strong>mkdir</strong>命令。在Hadoop上创建目录与在Linux上创建目录类似，根目录用“&#x2F;”表示。下面是一些应用示例。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">hadoop fs -<span class="hljs-built_in">mkdir</span> /test<br><span class="hljs-comment">#创建文件及其子目录</span><br>hadoop fs -<span class="hljs-built_in">mkdir</span> -p /dira/dirb<br></code></pre></td></tr></table></figure>

<h3 id="查看文件列表"><a href="#查看文件列表" class="headerlink" title="查看文件列表"></a>查看文件列表</h3><p>与Linux的ls命令类似，Hadoop也有一条查看文件列表的命令，其完整用法是hadoop fs ls ＜args＞，其中＜args＞表示可选参数。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#显示文件及其子目录</span><br>hadoop fs -<span class="hljs-built_in">ls</span> /<br></code></pre></td></tr></table></figure>

<h3 id="上传文件到HDFS"><a href="#上传文件到HDFS" class="headerlink" title="上传文件到HDFS"></a>上传文件到HDFS</h3><p>将文件从本地复制到HDFS集群称为文件上传。有两种命令可以使用，一种是“<strong>hadoop fs -put</strong>”，另一种是“<strong>hadoop fs -copyFromLocal</strong>”。</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gradle">#将a.data上传到HDFS <span class="hljs-regexp">/test/i</span>nput目录下<br>hadoop fs -put <span class="hljs-regexp">/home/</span>a.data <span class="hljs-regexp">/test/i</span>nput<br></code></pre></td></tr></table></figure>

<h3 id="下载文件到本地"><a href="#下载文件到本地" class="headerlink" title="下载文件到本地"></a><strong>下载文件到本地</strong></h3><p>将文件从HDFS集群复制到本地称为文件下载。有两种命令可以使用，一种是“hadoop fs -get”，另一种是“hadoop fs -copyToLocal”。</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gradle">#将HDFS上的<span class="hljs-regexp">/test/i</span>nput<span class="hljs-regexp">/a.data 下载到 /</span>home/hadoop目录下<br>Hadoop fs - get <span class="hljs-regexp">/test/i</span>nput<span class="hljs-regexp">/a.data /</span>home/hadoop<br></code></pre></td></tr></table></figure>

<h3 id="查看HDFS文件内容"><a href="#查看HDFS文件内容" class="headerlink" title="查看HDFS文件内容"></a><strong>查看HDFS文件内容</strong></h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">hadoop fs -text <span class="hljs-regexp">/input/</span>a.txt<br>hadoop fs -cat <span class="hljs-regexp">/input/</span>b.txt<br>hadoop fs -tail <span class="hljs-regexp">/input/</span>c.txt<br></code></pre></td></tr></table></figure>

<h3 id="删除HDFS文件"><a href="#删除HDFS文件" class="headerlink" title="删除HDFS文件"></a>删除HDFS文件</h3><p>可以用“hadoop fs -rm”删除HDFS集群中的文件。</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata">hadoop fs -<span class="hljs-keyword">rm</span> /<span class="hljs-keyword">test</span>/<span class="hljs-keyword">input</span>/a.txt<br></code></pre></td></tr></table></figure>

<h1 id="五、Hadoop计算"><a href="#五、Hadoop计算" class="headerlink" title="五、Hadoop计算"></a>五、Hadoop计算</h1><h2 id="MapReduce通俗解释"><a href="#MapReduce通俗解释" class="headerlink" title="MapReduce通俗解释"></a>MapReduce通俗解释</h2><p>图书馆要清点图书数量，有10个书架，管理员为了加快统计速度，找来了10个同学，每个同学负责统计一个书架的图书数量。</p>
<p>张同学统计 书架1</p>
<p>王同学统计 书架2</p>
<p>刘同学统计 书架3</p>
<p>……</p>
<p>过了一会儿，10个同学陆续到管理员这汇报自己的统计数字，管理员把各个数字加起来，就得到了图书总数。</p>
<p>这个过程就可以理解为MapReduce的工作过程。</p>
<p><strong>两个核心操作：</strong></p>
<ul>
<li>map。管理员分配哪个同学统计哪个书架，每个同学都进行相同的“统计”操作，这个过程就是map。</li>
<li>reduce。每个同学的结果进行汇总，这个过程是reduce。</li>
</ul>
<h2 id="过程拆解"><a href="#过程拆解" class="headerlink" title="过程拆解"></a>过程拆解</h2><p>下面通过一个景点案例（单词统计）看MapReduce是如何工作的。</p>
<p>有一个文本文件，被分成了4份，分别放到了4台服务器中存储</p>
<p>Text1：the weather is good</p>
<p>Text2：today is good</p>
<p>Text3：good weather is good</p>
<p>Text4：today has good weather</p>
<p>现在要统计出每个单词的出现次数。</p>
<h3 id="拆分单词（map）"><a href="#拆分单词（map）" class="headerlink" title="拆分单词（map）"></a>拆分单词（map）</h3><h1 id="六、项目-好友推荐"><a href="#六、项目-好友推荐" class="headerlink" title="六、项目-好友推荐"></a>六、项目-好友推荐</h1><h2 id="需求简介"><a href="#需求简介" class="headerlink" title="需求简介"></a>需求简介</h2><p>在现实生活中，如果你的好友A和B都有一个共同的好友C，那么C很可能是你的潜在好友。如果C在你的朋友的关系中出现的次数越多，这种概率越大。</p>
<p><strong>问题描述</strong></p>
<p>给出以下数据，为每个人推荐好友，按照共同好友的多少排序(最多10个)</p>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311446271.png" srcset="/img/loading.gif" lazyload alt="1"></p>
<p><strong>测试数据</strong></p>
<p><strong>输出格式</strong></p>
<p>用户1 好友推荐1, 好友推荐2, 好友推荐3</p>
<p>用户2 好友推荐4,好友推荐5, 好友推荐6</p>
<p>按照推荐度排序，每个用户最多推荐10个。</p>
<h2 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h2><p>社交网站上的各个用户以及用户之间的相互关注可以抽象为一个图。以下图为例：</p>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311447354.jpg" srcset="/img/loading.gif" lazyload alt="2"></p>
<p>顶点A、B、C到I分别是社交网站的用户，两顶点之间的边表示两顶点代表的用户之间相互关注。那么如何根据用户之间相互关注所构成的图，来向每个用户推荐好友呢？</p>
<p>现在我们以上图为例，介绍下如何利用用户之间相互关注所构成的图，来向每个用户推荐好友。首先我们不得不假设的是如果两用户之间相互关注，那么我们认为他们认识或者说是现实中的好友，至少应该认识。假设我们现在需要向用户I推荐好友，我们发现用户I的好友有H、G、C。其中H的好友还有A，G的好友还有F，C的好友还有B、F。那么用户I、H、G、C、A、B、F极有可能是同一个圈子里的人。我们应该把用户A、B、F推荐给用户I认识。进一步的想，用户F跟两位I的好友C、G是好友，而用户A、B都分别只跟一位I的好友是好友，那么相对于A、B来说，F当然更应该推荐给用户I认识。</p>
<h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><h3 id="数据清洗："><a href="#数据清洗：" class="headerlink" title="数据清洗："></a><strong>数据清洗：</strong></h3><p>在Map过程中过滤掉每行通过”\t”分割后长度不为2的数据。</p>
<h3 id="Map设计："><a href="#Map设计：" class="headerlink" title="Map设计："></a>Map设计：</h3><ol>
<li>从单行数据（0 1,3,4,5,7）入手。</li>
<li>得出1. 0和1是直接好友，1和3是间接好友。</li>
<li>依照直接或者间接关系,打上标签<ul>
<li>如0号和1号是直接好友,我们建立<strong>键值对</strong>,打上标签为(<strong>0 : 1,1</strong>)</li>
<li>如1号和3号暂时是间接好友,我们建立<strong>键值对</strong>,打上标签为(<strong>0 : 2,3</strong>)</li>
</ul>
</li>
</ol>
<p><strong>以此类推:</strong></p>
<ul>
<li>直接好友：首先对用户0号本身，将0与其好友打上标签。<br>结果为：(0: <strong>1</strong>,1) (0: <strong>1</strong>,3) (0: <strong>1</strong>,4) (0: <strong>1</strong>,5) (0: <strong>1</strong>,7)</li>
<li>间接好友：然后对于好友集合:笛卡尔乘积，互相打上标签2。1,3,4,5,7 X 1,3,4,5,7。(1: <strong>2</strong>,3) (3: <strong>2</strong>,1) (1: <strong>2</strong>,4) (4: <strong>2</strong>,1) 等…….</li>
</ul>
<p><strong>然后对于好友集合:笛卡尔乘积</strong></p>
<p>最终处理完成</p>
<p><img src="https://raw.githubusercontent.com/fyyuestc/Images/main/img/202207311447502.png" srcset="/img/loading.gif" lazyload alt="3"></p>
<h3 id="Reduce设计"><a href="#Reduce设计" class="headerlink" title="Reduce设计"></a>Reduce设计</h3><p>Reduce接收分三种情况：</p>
<ul>
<li><strong>第一种情况:(0,1,1),(0,1,3),(0,1,4)<br><strong>对于这情况(标签为1)-直接好友<br>如:(0: <strong>1</strong>,1) 告诉了我们</strong>0</strong>用户和<strong>1</strong>用户肯定是直接好友,所以我们不用把<strong>1</strong>用户推荐给<strong>0</strong>用户。</li>
<li><strong>第二种情况(标签为2)</strong><br><strong>说明是暂时的间接好友</strong><br><strong>如:(1: 2,4) 告诉了我们1用户和4用户暂时是间接好友关系,可以考虑进行推荐,我们的reduce过程便可以进行记录</strong></li>
<li><strong>第三种情况</strong>：如果又来了一个(1: <strong>2</strong>,4)呢?这说明了什么?<br><strong>说明1和4有两个共同好友</strong></li>
<li><strong>第四种情况</strong>：如果之后又出现(1: 1,4)呢?<br><strong>这说明1和4的好友关系被拆穿了,他们已经互相认识了,我们不再将4推荐给1了</strong></li>
</ul>
<p>实现：接收map传递的键值对,要求key为<strong>0</strong> 如 (0: <strong>2</strong>,3)</p>
<ol>
<li>创建一个容器进行记录(用HashMap**)(**<strong>用户id:共同好友数)</strong></li>
<li>如果标签为<strong>1</strong>,则置共同好友数为**-1,表示标记为黑名单**,因为他们本来就认识,之后一并移除</li>
<li>如果标签为<strong>2并且没在黑名单</strong>,便进行记录计数</li>
<li>如 map.put(3,1)表示3与之有一个共同好友,再来一个就是map.put(3,1+1)</li>
</ol>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/PersonalSummary/">#PersonalSummary</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Hadoop-个人总结</div>
      <div>http://example.com/2022/07/31/Hadoop-个人总结/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Fyy</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年7月31日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/07/31/Spark-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/" title="Spark-个人总结">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Spark-个人总结</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9D%A2%E7%BB%8F-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/" title="分布式面经-个人总结">
                        <span class="hidden-mobile">分布式面经-个人总结</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  

  

  

  

  

  

  
    
  




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="/js/leancloud.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
